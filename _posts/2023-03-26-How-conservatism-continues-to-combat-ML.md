## How conservatism continues to combat ML



Recently there was an article published in nature, about the use of a machine-learning algorithm for testing COVID travelers. 
Lately, if you had an opportunity to travel internationally, you will agree with me that the hours of touchdown have increased drastically. 
Well, I agree that in COVID-19 times, testing and documentation are inevitable. 
This transition in the travel industry was adapted much easily in larger economies. 
But smaller nations suffered and continue to suffer to provide enough medical assistance. 
The shortcomings of insufficient testing facilities had a larger impact. They played by the blunt rules of the border closure.

![image](https://user-images.githubusercontent.com/92452836/227815227-b08f5918-8442-40c2-a954-78088889b7ba.png)


If out of 140 passengers in a flight the algorithm predicts 50 most in risk, optimization of resources. 
I would say this is a multiway solution. Intelligent use of resources, reduced time of touchdown and faster processing. 
But as decades of work in statistics and computer science suggests, the prediction might be just locked in the phase of pandemic last year. 
If there are 5400 AI experts in the world right now, there exists 4 million of them that prefer conservative approach. 
Are we considering a shift back to the long hours of travelling? 
Or are we too traditional to not accept a strategy that stays a step ahead to predict the right passenger to test?

Today common man is surrounded with ML applications intentionally or unintentionally.
For example laptops, let it be Mac or Windowâ€™s carriers are built-in with ML predictors to reduce the time of access to the DRAM. 
The predictor based on its training datasets is learnt to predict the exact location of demand access from not so infinite Memory storage. 
What happens if the prediction is incorrect? The traditional search operation works as backup until the data is recovered to lower memory hierarchies. 
We are gaining on the time of the search for 80% of the times the predictor predicts correctly.

However, can we really take the 20% chance if the predictor is predicting if an infant requires oxygen supply to avoid mortalities? 
Even though biomedical is one of the keenest areas that computer scientists are looking to collaborate with, their rate of acceptance in real-life scenarios is way less.
Thousands of researchers defend their contribution to the medical community but its acceptance among the doctors is questionable considering the risk of misprediction on human life. 
Most of the medical community is seen to be skeptical about implementing such technology as the future of medicine. 
They support the research but would be uncomfortable for practical implementation.
Tesla Bot, a humanoid robot announced by Elon musk, to be designed as a friendly bot that can perform menial tasks of repetition and boredom. 
In a pre-explored domain of Pepper and ATLAS, Musk entered with not so novel addition.
Although this launch was not so explosive, his inner objective was to eventually make an autonomous driver for the autonomous vehicle.
The gap that an autonomous vehicle is not able to cover with the current technology could interestingly be cancelled out with two autonomous machines working synchronously. Chances of risk reduced significantly while maintaining the promise of automatism. 
But will I buy so much junk for my garage when I know I can do better at lower risk on life (and easy on my pocket) ?
